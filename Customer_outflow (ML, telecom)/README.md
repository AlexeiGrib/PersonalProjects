# Описание проекта "Отток клиентов".

## Цель проекта: 
 предсказание ухода клиента по истории его платежей, информации о договоре и используемых услугах, а также некоторой персональной информацией о нём. Целевой метрикой проекта является ROC-AUC. Для предоставления отчёта руководству компании и интерпретиации результатов работы модели также требуется посчитать метрику Accuracy. 

## Задачи проекта:

1. Разведывательный анализ данных.

2. Предобработка данных и генерация новых признаков.

3. Подбор оптимальной модели и её гиперпараметров, оценка качества работы модели на отложенной выборке.

4. Подготовка отчёта для руководства компании.

## Инструменты:

1. pandas
2. numpy
3. sklearn.train_test_split
4. sklearn.OrdinalEncoder
5. sklearn.StandardScaler
6. sklearn.GridSearchCV
7. sklearn.RandomForestClassifier
8. sklearn.LogisticRegression
9. CatBoostClassifier
10. LGBMClassifier
11. sklearn.roc_auc_score
12. sklearn.accuracy_score
13. sklearn.precision_score
14. sklearn.recall_score
15. sklearn.roc_curve
16. sklearn.confusion_matrix
19. random
20. seaborn
21. matplotlib

## Основные результаты проекта:

1. Проведено первичное знакомство с данными, исследованы наборы данных на предмет количества признаков/объектов, типов данных, наличия дефектов в данных (пропуски/дубликаты и прочее), а также намечены некоторые направления предобработки данных.
2. Данные собраны в единую аналитическую таблицу, образовывашиеся при этом пропуски были эмпирически заменены на признак отсутствия у клиента той или иной услуги в целях недопущения искажения бизнес-логики в данных, выполнены требуемые преобразования данных (в дату из строчного, в численный из строчного и др.), заменены отсутствующие значения в дате окончания договора на дату формирования выборки, в явном виде определён целевой признак. С помощью признаков даты начала и окончания сотрудничества клиента с компанией был рассчитан новый признак длительности жизни клиента в компании, ненужные признаки были удалены из набора данных. Выявлены 11 клиентов с длительностью контракта, равной нулю, для которых признак TotalCharges принимал пустое значение. Такие неявные пропуски были заменены нулями, так как эти клиенты заключили свои договоры с компанией в день формирования выгрузки и ещё не успели внести первые платежи. Набор данных был разделён на обучающую и тестовую выборки в соотношении 80/20. Категориальные переменные были закодированы в числовом виде с помощью техники OrdinalEncoder, непрерывные численные признаки были нормированы с помощью техники StandardScaler. Проведён корреляционный анализ признаков на предмет наличия мультиколлинеарности. По итогу анализа было принято решение об удалении признака TotalCharges из обучающей и тестовой выборок, так как он сильно коррелирует с признаком Life_Time, который в свою очередь сильнее коррелирует с целевым признаком, чем признак TotalCharges. 
3. Протестированы и сравнены между собой 4 алгоритма машинного обучения: RandomForestClassifier, LogisticRegression, CatBoostClassifier и LGBMClassifier. На этапе моделирования был произведён отбор признаков по степени их важности относительно целевого признака с помощью feature_importances. Перед отбором признаков мы условились, что значимым будет считаться признак, чья важность в модели равна или выше 0.05. К значимым признакам в модели были отнесены: Life_Time, Type, MonthlyCharges, OnlineSecurity, InternetService, TechSupport. К незначимым признакам были отнесены: OnlineBackup, PaymentMethod, PaperlessBilling, DeviceProtection, MultipleLines, SeniorCitizen, StreamingMovies, StreamingTV, Partner, gender, Dependents. Результаты работы моделей:

|Алгоритм               |ROC-AUC|Accuracy |
|:----------------------|:------|:--------|
|RandomForestClassifier |0.8798 |0.8346   |
|LogisticRegression     |0.8535 |0.7544   |
|CatBoostClassifier     |0.9468 |0.8964   |
|LGBMClassifier         |0.9437 |0.8850   |

Лучший результат продемонстрировала модель CatBoostClassifier - ROC-AUC на уровне 0.9468, Accuracy - на уровне 0.8964. 

Результаты её работы были протестированы более детально с помощью других метрик классификации, матрицы ошибок, ROC-кривой, а также сравнением с случайной и константными моделями. Отметим некоторые результаты:


- Количество истинноположительных ответов = 249. Следовательно, модель предсказала уход клиента, который действительно ушёл, 249 раз.


- Количество истинноотрицательных ответов = 1 014. Следовательно, модель предсказала сохранение клиента, который действительно не ушёл, 1 014 раз.


- Количество ложноположительных ответов = 22. Следовательно, модель совершила ошибку первого рода - предсказала уход клиента, который в действительности не ушёл - 22 раза.


- Количество ложиноотрицательных ответов = 124. Следовательно, модель совершила ошибку второго рода - предсказала сохранение клиента, который в действительности ушёл - 124 раза.


- Исходя из анализа матрицы ошибок, можно заключить, модель предсказывает класс 1 (отток) лучше, чем класс 0 (не отток). Это находит своё отражение в том, что модель совершает меньше ошибок первого рода (предсказывая уход клиента тогда, когда он в действительно сохраняется), чем ошибок второго рода (предсказывая сохранение клиента, в то время как в действительности клиент уходит). Такой результат сложился из-за дисбаланса классов: в данных значительно больше клиентов, которые не ушли в отток, чем клиентов, которые покинули компанию.


- Метрика recall сложилась на уровне 0.6676. Следовательно, из всех действительно ушедших клиентов, которых модель смогла определить корректно, а также тех клиентов, которые ушли и которых модель определить не смогла, совершив ошибку второго рода (373 клиента), модель смогла правильно определить только около 66%, что является довольно неплохим результатом.


- Метрика precision сложилась на уровне 0.9188. Следовательно, из всех действительно ушедших клиентов, которых модель смогла определить, а также среди тех клиентов, которые на самом деле не ушли и уход которых модель предсказала, совершив ошибку первого рода (271 клиент), модель смогла правильно определить около 92%. Неплохое значение метрики обусловленно небольшим количеством ошибок первого рода - модель достаточно хорошо предсказывает уход клиента, но чаще ошибается с предсказанием клиентов, которые не уходят.


- Метрика TPR (доля истинноположительных ответов) сложилась на уровне 0.6676. Следовательно, в 67% случаев построенная модель будет успешно предсказывать объекты с классом 1 (уход клиента), что кажется довольно приятным результатом.


- Метрика FPR (доля ложноположительных ответов) сложилась на уровне 0.0212. Следовательно, только в 2% случаев построенная модель может ошибаться, предсказывая сохранение клиента. Следовательно, в 98% случаев модель успешно предскажет сохранение клиента.


- ROC-AUC для случайного классификатора - 0.4950, ROC-AUC на отложенной выборке для CatBoostClassifier - 0.9468. Построенная модель обеспечивает лучшее по сравнению со случайным классификатором значение метрик TPR и FPR и в целом предсказывает уход клиентов достаточно хорошо, так как допускает не слишком много много ошибок первого и второго рода.


- Accuracy для случайной модели - 0.5060, Accuracy для константной модели (класс 1) - 0.2647, Accuracy для константной модели (класс 0) - 0.7353, Accuracy на отложенной выборке для CatBoostClassifier - 0.8964. Константная модель также хуже предсказывает класс целевого признака, чем построенная модель.


Таким образом, построенная модель модель CatBoostClassifier с значениями метрик ROC-AUC на уровне 0.9468, Accuracy на уровне 0.8964. может быть рекомендована компании «Ниединогоразрыва.ком» в качестве оптимальной модели, которая достаточно хорошо предсказывает отток клиентов, делая немногочисленные ошибки первого и второго рода, и которая не требует длительного времени на обучение относительно других алгоритмов.
